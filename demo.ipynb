{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import os\n",
    "\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an existing Dask cluster running already, set the scheduler address below. Otherwise, leave it to `None` and a local cluster will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/cjnolet/cuml5/lib/python3.7/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43799\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:37869/status' target='_blank'>http://127.0.0.1:37869/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>540.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:43799' processes=2 cores=2>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler_address = None #\"tcp://10.2.168.161:8786\"\n",
    "\n",
    "if scheduler_address is None:\n",
    "    from dask_cuda import LocalCUDACluster\n",
    "    cluster = LocalCUDACluster(n_workers = 2)\n",
    "    c = Client(cluster)\n",
    "else:\n",
    "    c = Client(scheduler_address)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nccl_example import get_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "from dask.distributed import default_client\n",
    "import random\n",
    "import ucp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommsBase:\n",
    "    \n",
    "    def __init__(self, comms_p2p = False):\n",
    "        self.client = default_client()\n",
    "\n",
    "        self.worker_addresses = self.get_workers_()\n",
    "\n",
    "    def get_workers_(self, parse_address = True):\n",
    "        \"\"\"\n",
    "        Return the list of workers parsed as [(address, port)]\n",
    "        \"\"\"\n",
    "        return list(self.client.has_what().keys())\n",
    "    \n",
    "    @staticmethod \n",
    "    def func_init_ucp_py(r):\n",
    "        print(\"Initiailizing ucp PY\")\n",
    "        ucp.init()\n",
    "        \n",
    "        ucp_worker = ucp.get_ucp_worker()\n",
    "                    \n",
    "        print(\"WORKER POINTER (Python): \" + hex(ucp_worker))\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        *************************\n",
    "        This is failing!\n",
    "        \"\"\"\n",
    "        get_address(ucp_worker)\n",
    "\n",
    "        \"\"\"\n",
    "        *************************\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \n",
    "    def init_ucp(self):\n",
    "        \"\"\"\n",
    "        Use ucx-py to initialize ucp endpoints so that every \n",
    "        worker can communicate, point-to-point, with every other worker\n",
    "        \"\"\"\n",
    "        \n",
    "        f = [self.client.submit(CommsBase.func_init_ucp_py, random.random(), workers = [w])\n",
    "                for w in self.worker_addresses]\n",
    "        \n",
    "        wait(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dask_UCX_Demo(CommsBase):\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        super(Dask_UCX_Demo, self).__init__(comms_p2p = True)\n",
    "        self.client = client\n",
    "        \n",
    "        self.init_(1)\n",
    "        \n",
    "    def init_(self, verbose = 0):\n",
    "        self.init_ucp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Dask_UCX_Demo(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuml5 [conda env:cuml5]",
   "language": "python",
   "name": "conda-env-cuml5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
